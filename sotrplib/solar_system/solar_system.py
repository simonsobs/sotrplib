import re
from datetime import datetime, timezone

import numpy as np
import pandas as pd
import structlog
from astropy import units as u
from astropy.coordinates import SkyCoord
from skyfield.api import load, wgs84
from skyfield.constants import GM_SUN_Pitjeva_2005_km3_s2 as GM_SUN
from skyfield.data import mpc
from structlog.types import FilteringBoundLogger
from tqdm import tqdm

from sotrplib.maps.core import ProcessableMap
from sotrplib.sources.sources import RegisteredSource


def create_observer(
    lat: u.Quantity[u.deg] = -22.96098 * u.deg,
    lon: u.Quantity[u.deg] = -67.7876 * u.deg,
    elev: u.Quantity[u.m] = 5180 * u.m,
) -> wgs84.latlon:
    """Create a Skyfield observer for the Simons Observatory LAT site."""
    return wgs84.latlon(
        lat.to_value(u.deg), lon.to_value(u.deg), elevation_m=elev.to_value(u.m)
    )


## need to normalize the names in Paul's file to the MPC format
## warning! this doesn't work with comets (probably fine, but we wont have comet ephemerides)
def normalize_asteroid_name(name: str) -> str:
    """
    Convert asteroid names such as:
        '3552 Don Quixote (1983 SA)' → '(3552) Don Quixote'
        '7335 (1989 JA)'             → '(7335) 1989 JA'
    """
    # Extract leading number and the rest
    m = re.match(r"^\s*(\d+)\s*(.*)$", name)
    if not m:
        return name  # fallback if pattern is unexpected

    number, rest = m.groups()

    # Extract provisional designation at end e.g. (1991 CS)
    provisional = None
    m2 = re.search(r"\(([^)]+)\)\s*$", rest)
    if m2:
        provisional = m2.group(1)
        rest = rest[: m2.start()].strip()  # remove the parentheses section

    # Determine final name
    if rest:  # there's a real name
        final_name = rest
    else:  # no real name -> use the provisional designation
        final_name = provisional if provisional else ""

    if final_name:
        return f"({number}) {final_name}"
    else:
        return f"({number})"


def generate_mpc_orbital_database(
    mpcorb_dat_file,
    asteroid_flux_estimates_file: str = "solar_system_objects.txt",
    output: str = "mpc_orbital_params_bright_asteroids.csv",
    flux_min: u.Quantity[u.mJy] = 10 * u.mJy,
    log: FilteringBoundLogger | None = None,
):
    """
    MPC orb catalog from https://www.minorplanetcenter.net/iau/MPCORB.html
    Asteroid flux estimates from Paul Chichura, SPT. estimated at 150 GHz at closest approach to Earth.
    """
    log = log or structlog.get_logger()
    log = log.bind(function="solar_system.generate_mpc_orbital_database")
    sso_name, _, _, maxflux = np.loadtxt(
        asteroid_flux_estimates_file, delimiter="\t", dtype="str", unpack=True
    )
    maxflux = np.asarray(maxflux, dtype=float) * u.mJy
    bright_sso_names = []
    for i in range(len(sso_name)):
        if (
            (maxflux[i] > flux_min)
            & (~sso_name[i].startswith("C"))
            & (~sso_name[i].startswith("("))
        ):
            bright_sso_names.append(sso_name[i])
    log.info(
        "solar_system.generate_mpc_orbital_database.sso_estimates_loaded",
        n_bright_asterids=len(bright_sso_names),
        flux_min=flux_min.to_value(u.mJy),
        flux_units=str(flux_min.unit),
    )

    with load.open(mpcorb_dat_file) as f:
        minor_planets = mpc.load_mpcorb_dataframe(f)

    log.info(
        "solar_system.generate_mpc_orbital_database.mpcorb_loaded",
        n_minor_planets=len(minor_planets),
    )

    # Filtering the orbits dataframe to avoid triggering
    # an `EphemerisRangeError` on ill-defined orbits.
    bad_orbits = minor_planets.semimajor_axis_au.isnull()
    minor_planets = minor_planets[~bad_orbits]

    ## get mpc file designations and compare to our bright sso names
    mpc_file_des = set(minor_planets.designation.values)
    new_db = []
    for name in tqdm(bright_sso_names, desc="Generating MPC orbital database"):
        des = normalize_asteroid_name(name)
        # Skip if designation is not in the MPC table
        if des not in mpc_file_des:
            continue
        # Append the row as a dict or Series
        row = minor_planets.loc[minor_planets.designation == des].iloc[0]
        new_db.append(row)
    new_db_df = pd.DataFrame(new_db)
    new_db_df.to_csv(output, index=False)
    log.info(
        "solar_system.generate_mpc_orbital_database.database_generated",
        output_file=output,
        n_asteroids=len(new_db_df),
    )

    return


def load_mpc_orbital_database(
    mpc_database_path: str = "mpc_orbital_params_bright_asteroids.csv",
):
    """Load the MPC orbital database from the specified path.
    This takes the CSV file generated by sotrplib.solar_system.generate_mpc_orbital_database
    """
    df = pd.read_csv(mpc_database_path, dtype=str)

    ## convert to floats where possible. needed for skyfield
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="ignore")

    return df


def get_sso_ephems_at_time(
    orbital_df: pd.DataFrame,
    time: datetime | list[datetime],
    observer: wgs84.latlon,
    log: FilteringBoundLogger | None = None,
    planets: list[str] = [
        "Mercury",
        "Venus",
        "Mars",
        "Jupiter",
        "Saturn",
        "Uranus",
        "Neptune",
    ],
) -> dict:
    """Get ephemerides for solar system objects in the provided dataframe at the specified times.

    Parameters
    ----------
    df : pd.DataFrame
        DataFrame containing orbital parameters of solar system objects.
    time : datetime | list[datetime]
        Time at which to compute the ephemerides. Should be timezone-aware.
    observer : wgs84.latlon
        Observer location for ephemeris calculations.
    log : FilteringBoundLogger, optional
        Logger for logging information, by default None.
    planets: list[str] = ["Mercury", "Venus", "Mars", "Jupiter", "Saturn", "Uranus", "Neptune"]
        List of planet names to include in the ephemerides.

    Returns
    -------
    dict[str, np.ndarray]
        Dictionary mapping object designations to their ephemerides (Skyfield position objects).
        These have ra, dec and distance.
    """
    log = log or structlog.get_logger()
    log = log.bind(function="solar_system.get_sso_ephems_at_time")

    ts = load.timescale()
    skyfield_time = ts.from_datetimes(time if isinstance(time, list) else [time])

    eph = load("de440s.bsp")
    sun = eph["sun"]
    earth = eph["earth"]
    observer_topo = earth + observer

    ## SSO orbits are sun-centric. Add sun position.
    ## Compute the position of the observer on earth.
    ## then combine to get the SSO position as seen by the observer.
    ## see https://rhodesmill.org/skyfield/kepler-orbits.html
    sso_ephems = {}
    if orbital_df is not None:
        for sso in tqdm(orbital_df.iloc, desc="Computing SSO ephemerides"):
            designation = sso["designation"]
            sso_pos = sun + mpc.mpcorb_orbit(sso, ts, GM_SUN)
            ra, dec, distance = observer_topo.at(skyfield_time).observe(sso_pos).radec()

            sso_ephems[designation] = {}
            sso_ephems[designation]["pos"] = SkyCoord(
                ra=ra.degrees * u.deg, dec=dec.degrees * u.deg
            )
            sso_ephems[designation]["distance"] = distance.km * u.km
    else:
        log.warning(
            "No orbital data provided; skipping SSO ephemerides computation for non-planets."
        )

    for p in planets:
        planet_eph = eph[f"{p} Barycenter"]
        ra, dec, distance = observer_topo.at(skyfield_time).observe(planet_eph).radec()
        sso_ephems[p] = {}
        sso_ephems[p]["pos"] = SkyCoord(ra=ra.degrees * u.deg, dec=dec.degrees * u.deg)
        sso_ephems[p]["distance"] = distance.km * u.km

    log.info(
        "solar_system.get_sso_ephems_at_time.ephemerides_computed",
        n_objects=len(sso_ephems),
        time=time.isoformat()
        if isinstance(time, datetime)
        else [t.isoformat() for t in time],
    )

    return sso_ephems


def get_sso_in_map(
    input_map: ProcessableMap,
    orbital_df: pd.DataFrame,
    observer: wgs84.latlon,
    interp_factor: int = 10,
    log: FilteringBoundLogger | None = None,
) -> list[RegisteredSource]:
    """Get solar system objects that fall within the provided map.

    Parameters
    ----------
    input_map : ProcessableMap
        Map to check for solar system objects.
    orbital_df : pd.DataFrame
        DataFrame containing orbital parameters of solar system objects.
    observer : wgs84.latlon
        Observer location for ephemeris calculations.
    cross_match_radius : u.Quantity[u.arcmin], optional
        Radius for cross-matching objects with the map, by default 5 * u.arcmin
    log : FilteringBoundLogger, optional
        Logger for logging information, by default None.

    Returns
    -------
    sso_ephems : dict
        Dictionary mapping object designations to their ephemerides .
    """
    time_range = [
        np.amin(input_map.time_first[input_map.time_first > 0]),
        np.nanmean(input_map.time_mean[input_map.time_first > 0]),
        np.nanmax(input_map.time_last),
    ]
    x = np.arange(len(time_range))
    x_new = np.linspace(0, len(time_range) - 1, int(interp_factor * len(time_range)))
    interp_time_range = np.interp(x_new, x, time_range)

    sso_ephems = get_sso_ephems_at_time(
        orbital_df,
        time=[datetime.fromtimestamp(t, tz=timezone.utc) for t in interp_time_range],
        observer=observer,
        log=log,
    )
    sso_not_in_map = []
    for sso in sso_ephems:
        sso_coords = sso_ephems[sso]["pos"]
        y, x = input_map.flux.wcs.world_to_pixel(sso_coords)
        nx, ny = input_map.flux.shape
        x, y = np.round(x).astype(int), np.round(y).astype(int)
        inside = (x >= 0) & (y >= 0) & (x < nx) & (y < ny)
        result = np.zeros_like(x, dtype=bool)
        result[inside] = np.nan_to_num(input_map.flux[x[inside], y[inside]]).astype(
            bool
        )
        if not np.any(result):
            sso_not_in_map.append(sso)
        sso_ephems[sso]["pos"] = sso_coords[result]
        sso_ephems[sso]["distance"] = sso_ephems[sso]["distance"][result]
        sso_ephems[sso]["time"] = [
            datetime.fromtimestamp(t, tz=timezone.utc)
            for t in interp_time_range[result]
        ]

    for sso in sso_not_in_map:
        del sso_ephems[sso]

    return sso_ephems
